{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. What is PyTorch?"],"metadata":{"id":"kchifhCic5bc"}},{"cell_type":"markdown","source":["PyTorch is an open-source machine learning library developed by Facebook's AI Research lab.\n","\n","It provides a flexible and dynamic computational graph, which makes it particularly suited for research and prototyping.\n","\n","PyTorch is known for its simplicity and ease of use, making it a popular choice for both beginners and experienced researchers in the field of deep learning."],"metadata":{"id":"PNChsFFhdbcx"}},{"cell_type":"markdown","source":["**Key Features**:\n","\n","  * **Dynamic Computational Graph**: A **dynamic computation graph is constructed in real-time during runtime**, while a static graph is pre-defined before execution. The adaptability of dynamic graphs facilitates complex architectures and simplifies debugging, whereas static graphs can optimize performance but may lack flexibility for certain model structures.\n","  * **Tensors**: PyTorch operates on multi-dimensional arrays called tensors, which are similar to NumPy's ndarrays but **with the ability to run on GPUs**.\n","  * **Neural Network Module**: PyTorch **provides torch.nn module** to define and train neural networks.\n","  * **GPU Acceleration**: PyTorch **supports GPU acceleration**, allowing computations to be performed much faster than on a CPU."],"metadata":{"id":"LgYpL7hUdhqc"}},{"cell_type":"markdown","source":["# 2. Why use PyTorch?"],"metadata":{"id":"cAmEP2T4c8q9"}},{"cell_type":"markdown","source":["While NumPy is an essential tool for numerical operations in Python, PyTorch offers additional features tailored for deep learning and neural network research:"],"metadata":{"id":"qpKJXiJjdsiB"}},{"cell_type":"markdown","source":["**Autograd: Automatic Differentiation**\n","\n","* The most significant advantage of PyTorch over NumPy is its autograd system. **Autograd automatically computes the gradients or derivatives of operations**, which is essential for training neural networks using gradient-based optimization algorithms.\n","\n","* In deep learning, we often need to calculate the gradient of a loss function with respect to model parameters. **Manual computation can be error-prone and tedious**. Autograd simplifies this by automatically calculating gradients."],"metadata":{"id":"Qi4_inxiduSh"}},{"cell_type":"markdown","source":["##  Example:"],"metadata":{"id":"fEpS12tVeD5n"}},{"cell_type":"markdown","source":["Let's say we have a simple operation like $y = x^2$ as an example."],"metadata":{"id":"yXTf6qJNpvVZ"}},{"cell_type":"markdown","source":["NumPy (without Autograd)"],"metadata":{"id":"fGxKmr0lePs1"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Define a value\n","x_np = np.array([2.0])\n","\n","# Manually compute the gradient\n","dy_dx = 2 * x_np\n","\n","print(dy_dx)"],"metadata":{"id":"Xq62wIUUeUWv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca244a7f-4825-4fa2-cec6-a39e033a5fef","executionInfo":{"status":"ok","timestamp":1695168897781,"user_tz":-540,"elapsed":4,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[4.]\n"]}]},{"cell_type":"markdown","source":["PyTorch (with Autograd)"],"metadata":{"id":"LCKZY05zeFq5"}},{"cell_type":"code","source":["import torch\n","\n","# Define a tensor and set requires_grad=True to track computation with it\n","x_pt = torch.tensor([2.0], requires_grad=True)\n","\n","# Define an operation\n","y = x_pt ** 2\n","\n","# Compute gradients\n","y.backward()\n","\n","# Display gradient\n","print(x_pt.grad)"],"metadata":{"id":"zc0v9NYmeIar","colab":{"base_uri":"https://localhost:8080/"},"outputId":"644840b5-a561-4373-b0ab-40017f74750b","executionInfo":{"status":"ok","timestamp":1695168905609,"user_tz":-540,"elapsed":5029,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.])\n"]}]},{"cell_type":"markdown","source":["While this is a simple example, imagine having to compute gradients for complex operations and architectures manually."],"metadata":{"id":"qx-19noieY9z"}},{"cell_type":"markdown","source":["**Disabling Gradient Tracking**\n","\n","By default, all tensors with **requires_grad=True** are tracking their computational history and support gradient computation. However, there are some cases when we do not need to do that, for example, when we have trained the model and just want to apply it to some input data, i.e. we only want to do forward computations through the network. We can stop tracking computations by surrounding our computation code with **torch.no_grad()** block:"],"metadata":{"id":"2gGxfaY1Nq3Q"}},{"cell_type":"code","source":["x = torch.ones(5)  # input tensor\n","y = torch.zeros(3)  # expected output\n","w = torch.randn(5, 3, requires_grad=True)\n","b = torch.randn(3, requires_grad=True)\n","\n","print(x)\n","print(y)\n","print(w)\n","print(b)"],"metadata":{"id":"XlWTPL3SNgev","executionInfo":{"status":"ok","timestamp":1695168976301,"user_tz":-540,"elapsed":428,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b8d99e2-01e9-41bc-a8e8-755e7180df38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.])\n","tensor([0., 0., 0.])\n","tensor([[-0.0740,  0.9387, -0.2975],\n","        [-0.8013,  1.5158, -0.3892],\n","        [-0.7580,  0.6995, -0.5530],\n","        [ 0.5651, -0.5556, -0.4149],\n","        [ 0.8197,  1.5269,  0.7209]], requires_grad=True)\n","tensor([ 0.4277, -0.8232, -0.2301], requires_grad=True)\n"]}]},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","print(z.requires_grad)\n","\n","with torch.no_grad():\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmC6EJRIN5wF","executionInfo":{"status":"ok","timestamp":1695169030327,"user_tz":-540,"elapsed":8,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}},"outputId":"e24f6870-766e-4723-b928-6f554b4a9fe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"markdown","source":["Another way to achieve the same result is to use the **detach()** method on the tensor:"],"metadata":{"id":"n0OqSlqAOC35"}},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","z_det = z.detach()\n","print(z_det.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5I3cmNdOGGJ","executionInfo":{"status":"ok","timestamp":1694485737077,"user_tz":-540,"elapsed":290,"user":{"displayName":"­홍민기 | 인공지능학과 | 한양대(서울)","userId":"13840019901450441786"}},"outputId":"bf71f7a5-09e0-48fe-89aa-e05e1cd87a84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["There are reasons you might want to disable gradient tracking:\n","- To mark some parameters in your neural network as frozen parameters.\n","- To speed up computations when you are only doing forward pass, because computations on tensors that do not track gradients would be more efficient."],"metadata":{"id":"EkBYUU7WOPeH"}},{"cell_type":"markdown","source":["# 3. Handling **torch.Tensor**"],"metadata":{"id":"cjNGlug3eccd"}},{"cell_type":"markdown","source":["In PyTorch, the fundamental object used for almost all computational tasks is the Tensor. A **Tensor** is similar to NumPy's **ndarray** but with the **added capability to be used on a GPU for faster computations**. Tensors are multi-dimensional arrays and are at the core of PyTorch's design."],"metadata":{"id":"0raEateNfZgE"}},{"cell_type":"markdown","source":["## a. Creating Tensors"],"metadata":{"id":"gQZihPSbfdDa"}},{"cell_type":"markdown","source":["From Lists"],"metadata":{"id":"R6PRZzxEfgFL"}},{"cell_type":"code","source":["data = [[1, 2], [3, 4]]\n","tensor_from_data = torch.tensor(data)\n","\n","print(tensor_from_data)"],"metadata":{"id":"Sa3sURxZgVwG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fef76345-787c-48ac-a8b4-2f97817c61af","executionInfo":{"status":"ok","timestamp":1695169118847,"user_tz":-540,"elapsed":334,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}]},{"cell_type":"markdown","source":["From NumPy Arrays"],"metadata":{"id":"KimLkmhufh_T"}},{"cell_type":"code","source":["np_array = np.array(data)\n","print(np_array)\n","\n","tensor_from_numpy = torch.from_numpy(np_array)\n","print(tensor_from_numpy)"],"metadata":{"id":"RYippqM0gZbQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"326746ae-50cd-4069-cc28-190da240897d","executionInfo":{"status":"ok","timestamp":1695169121271,"user_tz":-540,"elapsed":2,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2]\n"," [3 4]]\n","tensor([[1, 2],\n","        [3, 4]])\n"]}]},{"cell_type":"markdown","source":["Using Built-in Functions"],"metadata":{"id":"IcVPJhhMfm7t"}},{"cell_type":"code","source":["tensor_zeros = torch.zeros(3, 3)\n","tensor_ones = torch.ones(3, 3)\n","tensor_eye = torch.eye(3)  # Identity matrix\n","tensor_rand = torch.rand(3, 3)  # Uniform random numbers between 0 and 1\n","\n","print(tensor_zeros)\n","print(tensor_ones)\n","print(tensor_eye)\n","print(tensor_rand)"],"metadata":{"id":"99iJgn8EgfTk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5547ba2e-70d9-4969-b3b4-829be96ccaca","executionInfo":{"status":"ok","timestamp":1695169141388,"user_tz":-540,"elapsed":320,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])\n","tensor([[0.2675, 0.4659, 0.0622],\n","        [0.1434, 0.9738, 0.0942],\n","        [0.3946, 0.4999, 0.8501]])\n"]}]},{"cell_type":"markdown","source":["## b. Tensor Operations"],"metadata":{"id":"Qsbt9pmFfqWN"}},{"cell_type":"markdown","source":["**Arithmetic Operations**\n","\n","Arithmetic operations in PyTorch are element-wise operations similar to those in NumPy."],"metadata":{"id":"TgGHLcQTfvg7"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3])\n","y = torch.tensor([4, 5, 6])\n","\n","# Element-wise addition\n","z1 = x + y  # or torch.add(x, y)\n","print(z1)\n","\n","# Element-wise subtraction\n","z2 = x - y  # or torch.sub(x, y)\n","print(z2)\n","\n","# Element-wise multiplication\n","z3 = x * y  # or torch.mul(x, y)\n","print(z3)\n","\n","# Element-wise division\n","z4 = x / y  # or torch.div(x, y)\n","print(z4)"],"metadata":{"id":"-3SRYAJcgkz6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d684a0d-c0fc-4d2a-927b-69e0aeab62f0","executionInfo":{"status":"ok","timestamp":1695169181399,"user_tz":-540,"elapsed":305,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([5, 7, 9])\n","tensor([-3, -3, -3])\n","tensor([ 4, 10, 18])\n","tensor([0.2500, 0.4000, 0.5000])\n"]}]},{"cell_type":"markdown","source":["**Reduction Operations**\n","\n","Reduction operations reduce the number of elements in a tensor."],"metadata":{"id":"JiYnjw-vfyHm"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3, 4])\n","\n","# Sum of all elements\n","sum_all = torch.sum(x)\n","print(sum_all)\n","\n","# Mean of all elements (for float tensor)\n","mean_all = torch.mean(x.float())\n","print(mean_all)\n","\n","# Max and Min values\n","max_val = torch.max(x).item()\n","min_val = torch.min(x).item()\n","print(max_val, min_val)"],"metadata":{"id":"OIInRQtVgmNg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8854c9cb-44b2-4a2a-d5ce-972c8d4069b7","executionInfo":{"status":"ok","timestamp":1695169230596,"user_tz":-540,"elapsed":329,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10)\n","tensor(2.5000)\n","4 1\n"]}]},{"cell_type":"markdown","source":["**Matrix Operations**\n","\n","Matrix operations are fundamental in deep learning, especially in neural network layers.\n","\n"],"metadata":{"id":"uXTS1-2uf0vk"}},{"cell_type":"code","source":["mat1 = torch.tensor([[1, 2], [3, 4]])\n","mat2 = torch.tensor([[2, 1], [1, 2]])\n","\n","# Matrix multiplication\n","matmul_result = torch.mm(mat1, mat2)\n","print(matmul_result)\n","\n","# Element-wise matrix multiplication\n","elementwise_mul = mat1 * mat2\n","print(elementwise_mul)\n","\n","# Matrix transpose\n","transpose_mat = torch.t(mat1)\n","print(transpose_mat)"],"metadata":{"id":"QN00yZgognfR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03c68d2f-bb2a-4791-c07c-9341c0320fbc","executionInfo":{"status":"ok","timestamp":1695169302646,"user_tz":-540,"elapsed":311,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 4,  5],\n","        [10, 11]])\n","tensor([[2, 2],\n","        [3, 8]])\n","tensor([[1, 3],\n","        [2, 4]])\n"]}]},{"cell_type":"markdown","source":["**Reshaping**\n","\n","Reshaping allows you to change the shape (number of dimensions and size along each dimension) of a tensor.\n","\n"],"metadata":{"id":"hVuZL9Bbf2bp"}},{"cell_type":"code","source":["x = torch.tensor([[1, 2], [3, 4]])\n","\n","# Reshape to 4x1 tensor\n","# This stacks the rows of 'x' into a single column.\n","reshaped = x.view(4, 1)\n","print(reshaped)\n","print(reshaped.shape)\n","\n","# Flatten the tensor\n","# This transforms 'x' into a 1D tensor by unrolling its values.\n","# The '-1' in view indicates to infer the size for that dimension based on the original tensor.\n","flattened = x.view(-1)\n","print(flattened)\n","print(flattened.shape)"],"metadata":{"id":"Z6OoByS2go_4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"568f385d-9a84-43c2-d808-978bb0a4a4ad","executionInfo":{"status":"ok","timestamp":1695169409754,"user_tz":-540,"elapsed":281,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1],\n","        [2],\n","        [3],\n","        [4]])\n","torch.Size([4, 1])\n","tensor([1, 2, 3, 4])\n","torch.Size([4])\n"]}]},{"cell_type":"markdown","source":["The reshape function is similar to **view** but provides more flexibility as it returns a new tensor with the desired shape. If the requested shape is compatible with the original tensor and no memory copy is needed, it will share the same data; otherwise, a copy will be made."],"metadata":{"id":"OYN49SE0jC91"}},{"cell_type":"code","source":["x_reshape = torch.tensor([1, 2, 3, 4, 5, 6])\n","reshaped_tensor = x_reshape.reshape(2, 3)\n","print(reshaped_tensor)\n","print(reshaped_tensor.shape)"],"metadata":{"id":"YBEosZh0jH3Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaae8a84-a839-4ce5-c4a6-e7a56637ebf1","executionInfo":{"status":"ok","timestamp":1694485881509,"user_tz":-540,"elapsed":4,"user":{"displayName":"­홍민기 | 인공지능학과 | 한양대(서울)","userId":"13840019901450441786"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","torch.Size([2, 3])\n"]}]},{"cell_type":"markdown","source":["**Squeeze** and **Unsqueeze**\n","\n","**squeeze** function removes dimensions of size 1 from a tensor's shape. It's useful to reduce unnecessary dimensions.\n","\n"],"metadata":{"id":"MuTJFkT2tkTt"}},{"cell_type":"code","source":["x = torch.tensor([[1], [2], [3]])\n","print(x.shape)\n","\n","squeezed_tensor = x.squeeze()\n","print(squeezed_tensor.shape)\n","print(x)\n","print(squeezed_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1S_2UBlt7XO","outputId":"12937ac3-f684-4bde-f9e2-2cbd2e2a393f","executionInfo":{"status":"ok","timestamp":1695169740118,"user_tz":-540,"elapsed":390,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1])\n","torch.Size([3])\n","tensor([[1],\n","        [2],\n","        [3]])\n","tensor([1, 2, 3])\n"]}]},{"cell_type":"markdown","source":["\n"," As the opposite of squeeze, **unsqueeze** function adds a dimension of size 1 to a tensor's shape at a specified position."],"metadata":{"id":"swu-ULRiuFMp"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3])\n","print(x.shape)\n","\n","unsqueezed_tensor1 = x.unsqueeze(0)\n","print(unsqueezed_tensor1)\n","print(unsqueezed_tensor1.shape)\n","\n","unsqueezed_tensor2 = x.unsqueeze(1)\n","print(unsqueezed_tensor2)\n","print(unsqueezed_tensor2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x817pCg2uGs_","outputId":"dfe5904a-8bac-4d75-db62-2e842c9149bd","executionInfo":{"status":"ok","timestamp":1695169807161,"user_tz":-540,"elapsed":279,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3])\n","tensor([[1, 2, 3]])\n","torch.Size([1, 3])\n","tensor([[1],\n","        [2],\n","        [3]])\n","torch.Size([3, 1])\n"]}]},{"cell_type":"markdown","source":["**Concatenation**\n","\n","You can concatenate multiple tensors along a specific dimension."],"metadata":{"id":"o3_D5oHrf3jh"}},{"cell_type":"code","source":["x = torch.tensor([1, 2, 3])\n","y = torch.tensor([4, 5, 6])\n","\n","# Concatenate along dimension 0\n","concatenated_dim0 = torch.cat([x, y], dim=0)\n","print(concatenated_dim0)\n","print(concatenated_dim0.shape)\n","\n","# If you have 2D tensors, you can concatenate along dimension 1 as well\n","x2 = x.unsqueeze(1)\n","y2 = y.unsqueeze(1)\n","print(x2, y2, sep='\\n')\n","print(x2.shape, y2.shape, sep='\\n')\n","\n","concatenated_dim1 = torch.cat([x2, y2], dim=1)\n","print(concatenated_dim1)\n","print(concatenated_dim1.shape)"],"metadata":{"id":"nDSodNytgqi3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05bbc8f6-5f85-4613-cd71-755487ec3d14","executionInfo":{"status":"ok","timestamp":1695169890110,"user_tz":-540,"elapsed":291,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4, 5, 6])\n","torch.Size([6])\n","tensor([[1],\n","        [2],\n","        [3]])\n","tensor([[4],\n","        [5],\n","        [6]])\n","torch.Size([3, 1])\n","torch.Size([3, 1])\n","tensor([[1, 4],\n","        [2, 5],\n","        [3, 6]])\n","torch.Size([3, 2])\n"]}]},{"cell_type":"markdown","source":["**Indexing, Slicing, Joining, and Mutating**\n","\n","These operations allow you to access and modify specific parts of a tensor.\n","\n"],"metadata":{"id":"u_lOKMgOf5_Q"}},{"cell_type":"code","source":["x = torch.tensor([10, 20, 30, 40, 50])\n","\n","# Indexing: Get the second element\n","second_element = x[1]\n","print(second_element)\n","\n","# Slicing: Get the second and third elements\n","slice_2_3 = x[1:3]\n","print(slice_2_3)\n","\n","# Joining: Stack tensors together\n","stacked = torch.stack([x, x])\n","print(stacked)\n","\n","# Mutating: Change the first element of x to 100\n","x[0] = 100\n","print(x)"],"metadata":{"id":"ZdEpWHcXgrsz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"434272eb-c0b7-4e2e-c88d-122859019461","executionInfo":{"status":"ok","timestamp":1694485885564,"user_tz":-540,"elapsed":376,"user":{"displayName":"­홍민기 | 인공지능학과 | 한양대(서울)","userId":"13840019901450441786"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(20)\n","tensor([20, 30])\n","tensor([[10, 20, 30, 40, 50],\n","        [10, 20, 30, 40, 50]])\n","tensor([100,  20,  30,  40,  50])\n"]}]},{"cell_type":"markdown","source":["## c. Broadcasting"],"metadata":{"id":"AsphD0_OgBAw"}},{"cell_type":"markdown","source":["PyTorch supports broadcasting, a feature borrowed from NumPy. It allows PyTorch to work with arrays of different shapes when performing arithmetic operations."],"metadata":{"id":"OBd1YtzegDmX"}},{"cell_type":"markdown","source":["### Examples"],"metadata":{"id":"xhBJ-HSNut53"}},{"cell_type":"markdown","source":["**Scalar and Tensor**\n","\n","Adding a scalar to a tensor broadcasts the scalar across all elements of the tensor."],"metadata":{"id":"OQGXRkHEuyCL"}},{"cell_type":"code","source":["import numpy as np\n","\n","a = np.random.randint(0,3,(3,1)) # (3,4)\n","b = np.random.randint(0,3,(4,)) # (1,4) -> (3,4)\n","print(a)\n","print(b)\n","\n","print(a+b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4mkAPEuAhQw","executionInfo":{"status":"ok","timestamp":1695184393038,"user_tz":-540,"elapsed":474,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}},"outputId":"3dbb84d8-36ed-4599-9005-4a0620194af7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1]\n"," [0]\n"," [1]]\n","[1 1 1 2]\n","[[2 2 2 3]\n"," [1 1 1 2]\n"," [2 2 2 3]]\n"]}]},{"cell_type":"code","source":["tensor = torch.tensor([1, 2, 3])\n","result = tensor + 2\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XceSd5Fru4D3","outputId":"64e63cdc-0ccb-4125-f3a8-71fd40c04ebc","executionInfo":{"status":"ok","timestamp":1694485889235,"user_tz":-540,"elapsed":320,"user":{"displayName":"­홍민기 | 인공지능학과 | 한양대(서울)","userId":"13840019901450441786"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 4, 5])\n"]}]},{"cell_type":"markdown","source":["**Tensors with Different Dimensions**\n","\n","Adding a tensor of shape [3, 1] to a tensor of shape [3] will broadcast the second tensor across the rows of the first one."],"metadata":{"id":"Q3qKkOyWu6tp"}},{"cell_type":"code","source":["tensor_a = torch.tensor([[1], [2], [3]]) # (3,1) -> (3, 3)\n","tensor_b = torch.tensor([4, 5, 6]) # (3,) -> (1,3) -> (3, 3)\n","print(tensor_a.shape, tensor_b.shape)\n","\n","result = tensor_a + tensor_b\n","print(result)\n","print(result.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3VWvqSAvBDH","outputId":"fc739401-feba-44b7-820e-85b9f9b8a9fa","executionInfo":{"status":"ok","timestamp":1695184495296,"user_tz":-540,"elapsed":396,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1]) torch.Size([3])\n","tensor([[5, 6, 7],\n","        [6, 7, 8],\n","        [7, 8, 9]])\n","torch.Size([3, 3])\n"]}]},{"cell_type":"markdown","source":["**Tensors with Mismatched Dimensions**\n","\n","Operations between tensors with mismatched dimensions where neither dimension is 1 will raise an error."],"metadata":{"id":"EP7Ka8q9vSXc"}},{"cell_type":"code","source":["tensor_c = torch.tensor([[1, 2], [3, 4]]) #(2, 2)\n","tensor_d = torch.tensor([1, 2, 3]) #(3,)\n","print(tensor_c.shape, tensor_d.shape)\n","\n","# This will raise an error: result = tensor_c + tensor_d\n","try:\n","    result = tensor_c + tensor_d\n","except RuntimeError as e:\n","    error_message = str(e)\n","    print(error_message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvCWXOdTvWPH","outputId":"806d5845-75b5-4068-fa62-dbf84981caf8","executionInfo":{"status":"ok","timestamp":1695184535776,"user_tz":-540,"elapsed":521,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2]) torch.Size([3])\n","The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n"]}]},{"cell_type":"markdown","source":["## d. Moving Tensors between CPU and GPU"],"metadata":{"id":"QnX_xDZ7gFok"}},{"cell_type":"code","source":["import torch\n","print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hv6rV-SLwSQO","outputId":"ab819703-c54f-485b-90cd-dfcfe9557a6f","executionInfo":{"status":"ok","timestamp":1695170740564,"user_tz":-540,"elapsed":285,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"markdown","source":["**Moving a Tensor to GPU**\n","\n","PyTorch uses CUDA (a parallel computing platform and application programming interface model created by NVIDIA) to enable GPU computations. To move a tensor to the GPU, the cuda() method is used."],"metadata":{"id":"PX0rYNgfgKV4"}},{"cell_type":"code","source":["# Create a tensor on CPU\n","tensor_cpu = torch.tensor([1, 2, 3])\n","print(tensor_cpu.device)\n","\n","# Move the tensor to GPU (if CUDA is available)\n","if torch.cuda.is_available():\n","    tensor_gpu = tensor_cpu.cuda()\n","    print(tensor_gpu.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhvUTYFRwRly","outputId":"3b3f25b8-be37-4beb-9753-b237ecf27c20","executionInfo":{"status":"ok","timestamp":1695170760240,"user_tz":-540,"elapsed":6039,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","cuda:0\n"]}]},{"cell_type":"markdown","source":["**Moving a Tensor to a Specific GPU**\n","\n","In systems with multiple GPUs, they are numbered as 0, 1, 2, etc. You can select a specific GPU by setting its ID. Once the device is set to a specific GPU ID, you can move the tensor to that GPU using the to() method."],"metadata":{"id":"-B_3q0nEw43k"}},{"cell_type":"code","source":["# Set the GPU ID (for this example, we'll set it to 0)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Move the tensor to the specified GPU\n","tensor_gpu_specific = tensor_cpu.to(device)\n","print(tensor_gpu_specific.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLBlZf3Pw-13","outputId":"5a4cda36-a9fe-44a6-8f42-fff020b5a5bf","executionInfo":{"status":"ok","timestamp":1695170829579,"user_tz":-540,"elapsed":400,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","cuda:0\n"]}]},{"cell_type":"markdown","source":["**Moving a Tensor back to CPU**\n","\n","Once the computations on the GPU are completed, you might want to move the results back to the CPU. This can be achieved using the cpu() method."],"metadata":{"id":"T0228-fyworo"}},{"cell_type":"code","source":["# Move the tensor back to CPU from GPU\n","tensor_cpu_again = tensor_gpu.cpu()\n","print(tensor_cpu_again.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4K8lmd-cwqyi","outputId":"b0135cb8-4292-4399-f0a2-12cdadc35e25","executionInfo":{"status":"ok","timestamp":1695170866702,"user_tz":-540,"elapsed":531,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["If the tensors are not on the same device, you cannot perform operations on them."],"metadata":{"id":"Dnv3xjFJxdsU"}},{"cell_type":"code","source":["# Assuming you have a CUDA-enabled GPU\n","if torch.cuda.is_available():\n","    # Create a tensor on the CPU\n","    tensor_cpu = torch.tensor([1, 2, 3])\n","\n","    # Move the tensor to GPU\n","    tensor_gpu = tensor_cpu.cuda()\n","\n","    # Attempt to add the CPU tensor and GPU tensor\n","    # This will raise an error because the tensors are on different devices\n","    try:\n","        result = tensor_cpu + tensor_gpu\n","    except RuntimeError as e:\n","        error_message = str(e)\n","        print(error_message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZUxbwdIxiHZ","outputId":"284e2471-6147-4e5b-af8f-aa8061b4b127","executionInfo":{"status":"ok","timestamp":1695184762775,"user_tz":-540,"elapsed":5654,"user":{"displayName":"­서정욱 | 인텔리전스컴퓨팅학과 | 한양대(서울)","userId":"13430591093418992857"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"]}]},{"cell_type":"markdown","source":["# 4. Exercise"],"metadata":{"id":"YF71zcuroXmq"}},{"cell_type":"markdown","source":["1. Create two tensors of size (3, 3) with random values. Multiply them element-wise."],"metadata":{"id":"NSHmfACoohZv"}},{"cell_type":"code","source":[],"metadata":{"id":"-ra84yddokcz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Create a tensor **A** of size (5, 3) and another tensor **B** of size (3,). Add them."],"metadata":{"id":"_UGOu1mmoqfv"}},{"cell_type":"code","source":[],"metadata":{"id":"mLeL9KLxoxxU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Create two tensors of size (4, 3) and (3, 2). Perform matrix multiplication."],"metadata":{"id":"K9vgaVvMoyJe"}},{"cell_type":"code","source":[],"metadata":{"id":"WOv71jmmo2oX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Create a tensor of size (2, 6). Reshape it to (3, 4)."],"metadata":{"id":"ztjBFrP6o5O_"}},{"cell_type":"code","source":[],"metadata":{"id":"TgNcV1aio7SW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Create a tensor **A** of size (5, 1) and another tensor **B** of size (5,). Perform element-wise multiplication."],"metadata":{"id":"71zW1KKJo-XF"}},{"cell_type":"code","source":[],"metadata":{"id":"aUDIpBHUpC_B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Create two tensors of size (3, 4). Transpose the second tensor and perform matrix multiplication."],"metadata":{"id":"NoGQuBgPpCq4"}},{"cell_type":"code","source":[],"metadata":{"id":"i5yTYcp4pFh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. Create a tensor of size (3, 1) and expand its size to (3, 4). Sum the elements along the second dimension."],"metadata":{"id":"onGizY85pGig"}},{"cell_type":"code","source":[],"metadata":{"id":"PIfhLB6TpKgE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8. Create a tensor of size (6, 5). Calculate the mean along the second dimension."],"metadata":{"id":"6Q9bSCM9pL7r"}},{"cell_type":"code","source":[],"metadata":{"id":"VCh7H308pLtK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["9. Create a tensor of size (4, 4). Extract the second and fourth row."],"metadata":{"id":"8y6RsNIYpOiF"}},{"cell_type":"code","source":[],"metadata":{"id":"XXuInXf7pQ9z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10. Calculate the outer product of two tensors of size (5,) and (3,).\n","\n","- *Search for the outer product function on Google!*"],"metadata":{"id":"7qFf8A-jpSIU"}},{"cell_type":"code","source":[],"metadata":{"id":"-4_Jnd1HpUU8"},"execution_count":null,"outputs":[]}]}